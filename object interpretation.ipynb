{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretable Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    OpenCV is not installed and cannot be used\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import brambox as bb\n",
    "import lightnet as ln\n",
    "import interpretability as ip\n",
    "from PIL import Image\n",
    "from PIL import ImageChops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Settings and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA enabled\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "bb.logger.setConsoleLevel('ERROR')             # Only show error log messages\n",
    "\n",
    "# Setting device\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA enabled')\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('CUDA not available')\n",
    "    \n",
    "# Variables\n",
    "anchorbox_threshold = 1.0\n",
    "detection_threshold = 0.5\n",
    "    \n",
    "# Path variables\n",
    "network_path = 'cfg/yolo.py'\n",
    "annos_path = 'data/VOCdevkit/VOC2007/Annotations/'\n",
    "weights_path = 'weights/yolov2-voc.pt'\n",
    "\n",
    "# Load annotations\n",
    "anno = bb.io.load('pandas', 'data/annotations.pkl')\n",
    "det = bb.io.load('pandas', 'data/detections.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Picking interesting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP FP:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class_label</th>\n",
       "      <th>id</th>\n",
       "      <th>x_top_left</th>\n",
       "      <th>y_top_left</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>confidence</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260260</th>\n",
       "      <td>VOC2007/JPEGImages/006993</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>199.793009</td>\n",
       "      <td>69.375368</td>\n",
       "      <td>241.700741</td>\n",
       "      <td>252.270258</td>\n",
       "      <td>0.967542</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135826</th>\n",
       "      <td>VOC2007/JPEGImages/003650</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>323.067078</td>\n",
       "      <td>199.635542</td>\n",
       "      <td>155.075220</td>\n",
       "      <td>180.827581</td>\n",
       "      <td>0.732909</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image class_label  id  x_top_left  y_top_left  \\\n",
       "260260  VOC2007/JPEGImages/006993     bicycle   0  199.793009   69.375368   \n",
       "135826  VOC2007/JPEGImages/003650     bicycle   0  323.067078  199.635542   \n",
       "\n",
       "             width      height  confidence     tp    fp  \n",
       "260260  241.700741  252.270258    0.967542  False  True  \n",
       "135826  155.075220  180.827581    0.732909  False  True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class_label</th>\n",
       "      <th>id</th>\n",
       "      <th>x_top_left</th>\n",
       "      <th>y_top_left</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>occluded</th>\n",
       "      <th>truncated</th>\n",
       "      <th>lost</th>\n",
       "      <th>difficult</th>\n",
       "      <th>ignore</th>\n",
       "      <th>detection</th>\n",
       "      <th>criteria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>VOC2007/JPEGImages/000111</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>VOC2007/JPEGImages/000111</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>VOC2007/JPEGImages/000111</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>VOC2007/JPEGImages/000111</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>VOC2007/JPEGImages/000111</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         image class_label  id  x_top_left  y_top_left  width  \\\n",
       "158  VOC2007/JPEGImages/000111     bicycle   0       333.0       192.0   30.0   \n",
       "159  VOC2007/JPEGImages/000111     bicycle   0       302.0       198.0   17.0   \n",
       "160  VOC2007/JPEGImages/000111     bicycle   0       242.0       197.0   19.0   \n",
       "161  VOC2007/JPEGImages/000111     bicycle   0       218.0       205.0   34.0   \n",
       "162  VOC2007/JPEGImages/000111     bicycle   0       174.0       192.0   17.0   \n",
       "\n",
       "     height  occluded  truncated   lost  difficult  ignore  detection  \\\n",
       "158    19.0       0.0        0.0  False       True    True        NaN   \n",
       "159    12.0       1.0        0.0  False       True    True        NaN   \n",
       "160    14.0       1.0        0.0  False       True    True        NaN   \n",
       "161    12.0       0.0        0.0  False       True    True        NaN   \n",
       "162    18.0       1.0        0.0  False       True    True        NaN   \n",
       "\n",
       "     criteria  \n",
       "158       0.0  \n",
       "159       0.0  \n",
       "160       0.0  \n",
       "161       0.0  \n",
       "162       0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_class = 'bicycle' # Which class to look at\n",
    "\n",
    "anno = anno[anno['class_label'] == my_class]\n",
    "det = det[det['class_label'] == my_class]\n",
    "\n",
    "pr = bb.stat.pr(det, anno, 0.75)  # IoU threshold of 0.5\n",
    "ap = bb.stat.ap(pr)\n",
    "\n",
    "# Find detection threshold with maximal F1\n",
    "f1 = bb.stat.fscore(pr)\n",
    "threshold = bb.stat.peak(f1)\n",
    "\n",
    "# Filter detections based on threshold (computed in previous step from F1-curve)\n",
    "filtered_det = det[det.confidence >= threshold.confidence].copy()\n",
    "\n",
    "# Compute TP,FP\n",
    "tpfp_det = bb.stat.match_det(filtered_det, anno, 0.5)\n",
    "# match_det() returns detections with a 'tp' and 'fp' column.\n",
    "print('TP FP:')\n",
    "display(tpfp_det[tpfp_det['fp']].sort_values(['confidence'], ascending=False))\n",
    "chosen_images = tpfp_det[tpfp_det['fp']].image.unique()\n",
    "\n",
    "# Compute FN\n",
    "fn_anno = bb.stat.match_anno(filtered_det, anno, 0.5)\n",
    "# match_anno() returns annotations with a 'detection' column that has the index of the matched detection\n",
    "# We use this to filter unmatched annotations (NaN as index)\n",
    "fn_anno = fn_anno[fn_anno.detection.isnull()]\n",
    "print('FN:')\n",
    "display(fn_anno.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Backprogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO       Loading weights from file [weights/yolov2-voc.pt]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 26, 169])\n",
      "torch.Size([1, 5, 169, 4])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([1, 5, 26, 169])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-61e2efe1fd7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#doe iest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdet_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdet_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Masterproef/Interpretable-Object-Detection/interpretability/run_model.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(params, args_anno, device)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Postprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_compose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReverseLetterbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightnet/data/transform/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Masterproef/Interpretable-Object-Detection/interpretability/utils/postprocess.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, network_output)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_network_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_network_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# [C, AnchorIdx]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore_thresh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 3"
     ]
    }
   ],
   "source": [
    "# Initialize network and load weights\n",
    "params = ln.engine.HyperParameters.from_file(network_path)\n",
    "params.network.load(weights_path)\n",
    "params.post[0].conf_thresh = detection_threshold   # Overwrite threshold\n",
    "\n",
    "gradients_as_arr_list = []\n",
    "chosen_images = ['VOC2007/JPEGImages/000002']\n",
    "\n",
    "for image in chosen_images:\n",
    "    # New path\n",
    "    new_path = annos_path + image.split('/')[-1] + '.xml'\n",
    "    \n",
    "    # Load annos\n",
    "    annos = bb.io.load('anno_pascalvoc', new_path, ip.identify)\n",
    "    \n",
    "    #doe iest\n",
    "    det_img, detections = ip.detect(params, new_path, device)\n",
    "    print(detections)\n",
    "    display(ip.utils.show_image(det_img))\n",
    "    \n",
    "    # Run model\n",
    "    params, img_tf, annos = ip.run_model(params, annos, new_path , device)\n",
    "    \n",
    "    image_one = Image.open('data/iets.jpg')\n",
    "    image_two = Image.open('data/iets2.jpg')\n",
    "\n",
    "    diff = ImageChops.difference(image_one, image_two)\n",
    "\n",
    "    if diff.getbbox():\n",
    "        print(\"images are different\")\n",
    "    else:\n",
    "        print(\"images are the same\")\n",
    "        \n",
    "    display(ip.utils.show_image(img_tf.data.cpu().numpy()[0]))\n",
    "\n",
    "    # Vanilla backprop\n",
    "    VBP = ip.backprop.VanillaBackprop(params, device)\n",
    "\n",
    "    # Generate gradients\n",
    "    gradients_as_arr = VBP.generate_gradients(params, img_tf, annos, device, anchorbox_threshold)\n",
    "    for gradient in gradients_as_arr:\n",
    "        gradients_as_arr_list.append(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show images on screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Normalize to grayscale and show images\n",
    "gradients_list = ip.utils.normalize(gradients_as_arr_list, True)\n",
    "for gradient in gradients_list:\n",
    "    display(ip.utils.show_image(gradient), ip.utils.show_image(gradient * img_tf.data.cpu().numpy()[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
