{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretable Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import brambox as bb\n",
    "import lightnet as ln\n",
    "import interpretability as ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "bb.logger.setConsoleLevel('ERROR')             # Only show error log messages\n",
    "\n",
    "# Setting device\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA enabled')\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('CUDA not available')\n",
    "    \n",
    "# Variables\n",
    "detection_threshold = 0.5\n",
    "    \n",
    "# Path variables\n",
    "network_path = 'cfg/yolo.py'\n",
    "annos_path = 'data/VOCdevkit/VOC2007/Annotations/'\n",
    "weights_path = 'weights/yolov2-voc.pt'\n",
    "\n",
    "# Load annotations\n",
    "anno = bb.io.load('pandas', 'data/annotations.pkl')\n",
    "det = bb.io.load('pandas', 'data/detections.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Picking interesting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP FP:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class_label</th>\n",
       "      <th>id</th>\n",
       "      <th>x_top_left</th>\n",
       "      <th>y_top_left</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>confidence</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260260</th>\n",
       "      <td>VOC2007/JPEGImages/006993</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>199.793009</td>\n",
       "      <td>69.375368</td>\n",
       "      <td>241.700741</td>\n",
       "      <td>252.270258</td>\n",
       "      <td>0.967542</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135826</th>\n",
       "      <td>VOC2007/JPEGImages/003650</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>323.067078</td>\n",
       "      <td>199.635542</td>\n",
       "      <td>155.075220</td>\n",
       "      <td>180.827581</td>\n",
       "      <td>0.732909</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66864</th>\n",
       "      <td>VOC2007/JPEGImages/001781</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>427.736869</td>\n",
       "      <td>55.376200</td>\n",
       "      <td>72.166264</td>\n",
       "      <td>223.371616</td>\n",
       "      <td>0.703741</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215233</th>\n",
       "      <td>VOC2007/JPEGImages/005745</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>-14.240210</td>\n",
       "      <td>270.846092</td>\n",
       "      <td>323.588298</td>\n",
       "      <td>178.814705</td>\n",
       "      <td>0.700215</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319336</th>\n",
       "      <td>VOC2007/JPEGImages/008540</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>305.806325</td>\n",
       "      <td>124.948868</td>\n",
       "      <td>115.829284</td>\n",
       "      <td>176.219298</td>\n",
       "      <td>0.661485</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image class_label  id  x_top_left  y_top_left  \\\n",
       "260260  VOC2007/JPEGImages/006993     bicycle   0  199.793009   69.375368   \n",
       "135826  VOC2007/JPEGImages/003650     bicycle   0  323.067078  199.635542   \n",
       "66864   VOC2007/JPEGImages/001781     bicycle   0  427.736869   55.376200   \n",
       "215233  VOC2007/JPEGImages/005745     bicycle   0  -14.240210  270.846092   \n",
       "319336  VOC2007/JPEGImages/008540     bicycle   0  305.806325  124.948868   \n",
       "\n",
       "             width      height  confidence     tp    fp  \n",
       "260260  241.700741  252.270258    0.967542  False  True  \n",
       "135826  155.075220  180.827581    0.732909  False  True  \n",
       "66864    72.166264  223.371616    0.703741  False  True  \n",
       "215233  323.588298  178.814705    0.700215  False  True  \n",
       "319336  115.829284  176.219298    0.661485  False  True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class_label</th>\n",
       "      <th>id</th>\n",
       "      <th>x_top_left</th>\n",
       "      <th>y_top_left</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>occluded</th>\n",
       "      <th>truncated</th>\n",
       "      <th>lost</th>\n",
       "      <th>difficult</th>\n",
       "      <th>ignore</th>\n",
       "      <th>detection</th>\n",
       "      <th>criteria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>VOC2007/JPEGImages/000111</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>VOC2007/JPEGImages/000111</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>VOC2007/JPEGImages/000111</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>VOC2007/JPEGImages/000111</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>VOC2007/JPEGImages/000111</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         image class_label  id  x_top_left  y_top_left  width  \\\n",
       "158  VOC2007/JPEGImages/000111     bicycle   0       333.0       192.0   30.0   \n",
       "159  VOC2007/JPEGImages/000111     bicycle   0       302.0       198.0   17.0   \n",
       "160  VOC2007/JPEGImages/000111     bicycle   0       242.0       197.0   19.0   \n",
       "161  VOC2007/JPEGImages/000111     bicycle   0       218.0       205.0   34.0   \n",
       "162  VOC2007/JPEGImages/000111     bicycle   0       174.0       192.0   17.0   \n",
       "\n",
       "     height  occluded  truncated   lost  difficult  ignore  detection  \\\n",
       "158    19.0       0.0        0.0  False       True    True        NaN   \n",
       "159    12.0       1.0        0.0  False       True    True        NaN   \n",
       "160    14.0       1.0        0.0  False       True    True        NaN   \n",
       "161    12.0       0.0        0.0  False       True    True        NaN   \n",
       "162    18.0       1.0        0.0  False       True    True        NaN   \n",
       "\n",
       "     criteria  \n",
       "158       0.0  \n",
       "159       0.0  \n",
       "160       0.0  \n",
       "161       0.0  \n",
       "162       0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_class = 'bicycle' # Which class to look at\n",
    "\n",
    "anno = anno[anno['class_label'] == my_class]\n",
    "det = det[det['class_label'] == my_class]\n",
    "\n",
    "pr = bb.stat.pr(det, anno, 0.5)  # IoU threshold of 0.5\n",
    "ap = bb.stat.ap(pr)\n",
    "\n",
    "# Find detection threshold with maximal F1\n",
    "f1 = bb.stat.fscore(pr)\n",
    "threshold = bb.stat.peak(f1)\n",
    "\n",
    "# Filter detections based on threshold (computed in previous step from F1-curve)\n",
    "filtered_det = det[det.confidence >= threshold.confidence].copy()\n",
    "\n",
    "# Compute TP,FP\n",
    "tpfp_det = bb.stat.match_det(filtered_det, anno, 0.5)\n",
    "# match_det() returns detections with a 'tp' and 'fp' column.\n",
    "print('TP FP:')\n",
    "display(tpfp_det[tpfp_det['fp']].sort_values(['confidence'], ascending=False).head())\n",
    "chosen_images = tpfp_det[tpfp_det['fp']].image.unique()\n",
    "\n",
    "# Compute FN\n",
    "fn_anno = bb.stat.match_anno(filtered_det, anno, 0.5)\n",
    "# match_anno() returns annotations with a 'detection' column that has the index of the matched detection\n",
    "# We use this to filter unmatched annotations (NaN as index)\n",
    "fn_anno = fn_anno[fn_anno.detection.isnull()]\n",
    "print('FN:')\n",
    "display(fn_anno.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Backprogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO       Loading weights from file [weights/yolov2-voc.pt]\n"
     ]
    }
   ],
   "source": [
    "# Initialize network and load weights\n",
    "params = ln.engine.HyperParameters.from_file(network_path)\n",
    "params.network.load(weights_path)\n",
    "params.post[0].conf_thresh = detection_threshold   # Overwrite threshold\n",
    "\n",
    "gradients_as_arr_list = []\n",
    "chosen_images = ['VOC2007/JPEGImages/000013']\n",
    "\n",
    "for image in chosen_images:\n",
    "    # New path\n",
    "    new_path = annos_path + image.split('/')[-1] + '.xml'\n",
    "    \n",
    "    # Load annos\n",
    "    annos = bb.io.load('anno_pascalvoc', new_path, ip.identify)\n",
    "    \n",
    "    # Get detections\n",
    "    det_img, detections = ip.detect(params, new_path, device, detection_threshold)\n",
    "    display(ip.utils.show_image(det_img))\n",
    "    detections.image = image\n",
    "    detections.image = detections.image.astype('category')\n",
    "    \n",
    "    # Run model\n",
    "    img_tf, annos = ip.transform(params, annos, new_path)\n",
    "\n",
    "    # Compute TP,FP\n",
    "    tpfp_det = bb.stat.match_det(detections, annos, detection_threshold)\n",
    "    # match_det() returns detections with a 'tp' and 'fp' column.\n",
    "\n",
    "    # Compute FN\n",
    "    fn_anno = bb.stat.match_anno(detections, annos, 0.0)\n",
    "    # match_anno() returns annotations with a 'detection' column that has the index of the matched detection\n",
    "    # We use this to filter unmatched annotations (NaN as index)\n",
    "    fn_anno = fn_anno[fn_anno.detection.isnull()]\n",
    "    \n",
    "    # Add status column\n",
    "    tpfp_det['status'] = 'FP'                     # Make all boxes FP\n",
    "    tpfp_det.loc[tpfp_det.tp, 'status'] = 'TP'  # Make TP boxes TP\n",
    "    fn_anno['status'] = 'FN'                     # Make FN boxes FN\n",
    "    \n",
    "    # Add extra columns to fn_anno to be able to combine dataframes\n",
    "    fn_anno['anchor_box'] = ''\n",
    "    fn_anno['confidence'] = ''\n",
    "\n",
    "    # Only keep necessary columns (to be able to combine dataframes)\n",
    "    boxes1 = tpfp_det[['image', 'class_label', 'x_top_left', 'y_top_left', 'width', 'height', 'confidence', 'anchor_box', 'status']]\n",
    "    boxes2 = fn_anno[['image', 'class_label', 'x_top_left', 'y_top_left', 'width', 'height', 'confidence', 'anchor_box', 'status']]\n",
    "\n",
    "    # Concatenate dataframes\n",
    "    boxes = bb.util.concat([boxes1, boxes2], sort=False, ignore_index=True)\n",
    "    \n",
    "    print('Detections:')\n",
    "    display(boxes)\n",
    "    \n",
    "    # Vanilla backprop\n",
    "    VBP = ip.backprop.VanillaBackprop(params, device)\n",
    "\n",
    "    # Generate gradients\n",
    "    gradients_as_arr = VBP.generate_gradients(params, img_tf, device, boxes, True, True)\n",
    "    for gradient in gradients_as_arr:\n",
    "        gradients_as_arr_list.append(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show images on screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Normalize to grayscale and show images\n",
    "gradients_list = ip.utils.normalize(gradients_as_arr_list, True)\n",
    "for gradient in gradients_list:\n",
    "    display(ip.utils.show_image(gradient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Masterproef",
   "language": "python",
   "name": "masterproef"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
